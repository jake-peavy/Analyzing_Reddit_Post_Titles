{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make two identical for-loops that do exactly the same thing that i totally could have made into a function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_posts = []\n",
    "after   = None\n",
    "\n",
    "for i in range(40):\n",
    "    if after == None:\n",
    "        params = {}\n",
    "    else:\n",
    "        params = {'after' : after}\n",
    "        \n",
    "    p_url = 'https://www.reddit.com/r/politics/.json'\n",
    "    p_res = requests.get(p_url, params=params, headers = {'User-agent': 'JP'})\n",
    "    if p_res.status_code == 200:\n",
    "        p_json = p_res.json()\n",
    "        p_posts.extend(p_json['data']['children'])\n",
    "        after  = p_json['data']['after']\n",
    "    else:\n",
    "        print(p_res.status_code)\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_posts = []\n",
    "after   = None\n",
    "\n",
    "for i in range(40):\n",
    "    if after == None:\n",
    "        params = {}\n",
    "    else:\n",
    "        params = {'after' : after}\n",
    "        \n",
    "    d_url = 'https://www.reddit.com/r/the_donald/.json'\n",
    "    d_res = requests.get(d_url, params=params, headers = {'User-agent': 'JP'})\n",
    "    if d_res.status_code == 200:\n",
    "        d_json = d_res.json()\n",
    "        d_posts.extend(d_json['data']['children'])\n",
    "        after  = d_json['data']['after']\n",
    "    else:\n",
    "        print(d_res.status_code)\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here's a function \n",
    "> it turns lists into a Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_list(lst):\n",
    "    \n",
    "    title_lst = []\n",
    "    sub_lst   = []\n",
    "    \n",
    "    i         = 0\n",
    "    \n",
    "    for _ in lst:\n",
    "        title_lst.append(lst[i]['data']['title'])\n",
    "        sub_lst.append(lst[i]['data']['subreddit'])\n",
    "        i += 1\n",
    "    new_dict = {'title': title_lst, 'subreddit': sub_lst}\n",
    "    df = pd.DataFrame(new_dict)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "don_df = df_from_list(d_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "poli_df = df_from_list(p_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([poli_df,don_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Discussion Thread: Supreme Court Nominee Brett...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We’re PolitiFact, the largest political fact-c...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support for Republicans and for Kavanaugh crum...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donald Trump Has Called People 'Mentally Retar...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Kavanaugh Nomination Must Be Paused. And H...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title subreddit\n",
       "0  Discussion Thread: Supreme Court Nominee Brett...  politics\n",
       "1  We’re PolitiFact, the largest political fact-c...  politics\n",
       "2  Support for Republicans and for Kavanaugh crum...  politics\n",
       "3  Donald Trump Has Called People 'Mentally Retar...  politics\n",
       "4  The Kavanaugh Nomination Must Be Paused. And H...  politics"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Data Frame to `CSV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = str(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-09-05 15:43:57.539375'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'scraped_{now}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv('scraped_2018-09-05 15:43:57.539375')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
